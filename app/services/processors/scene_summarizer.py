import base64
import io
import json
import os
from pathlib import Path
from PIL import Image
from openai import OpenAI
from loguru import logger
from app.schemas import ProductInput, SceneSummary
from app.core.config import settings

class SceneSummarizer:
    def __init__(self):
        self.api_key = settings.QWEN_API_KEY
        self.model_name = "qwen-vl-plus"
        self.client = OpenAI(
            api_key=self.api_key,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        )

    def encode_image(self, image_path: Path):
        """
        Resizes image to 512x512 and encodes to base64.
        """
        try:
            with Image.open(image_path) as img:
                return self._process_pil_image(img)
        except Exception as e:
            logger.error(f"Error processing image {image_path}: {e}")
            return None

    def _process_pil_image(self, img: Image.Image):
        """
        Helper to resize and encode a PIL Image object.
        """
        try:
            img = img.convert("RGB")
            img = img.resize((512, 512))
            buffered = io.BytesIO()
            img.save(buffered, format="JPEG")
            return base64.b64encode(buffered.getvalue()).decode('utf-8')
        except Exception as e:
            logger.error(f"Error encoding PIL image: {e}")
            return None

    def stitch_images_9_patch(self, image_paths: list[Path], output_path: Path = None) -> str:
        """
        å°†æœ€å¤š 9 å¼ å›¾ç‰‡æ‹¼æ¥æˆ 3x3 çš„ä¹å®«æ ¼ï¼Œè¿”å› base64 å­—ç¬¦ä¸²ã€‚
        å¦‚æœæä¾›äº† output_pathï¼Œåˆ™å°†æ‹¼æ¥åçš„å›¾ç‰‡ä¿å­˜åˆ°è¯¥è·¯å¾„ã€‚
        """
        grid_size = 3
        single_img_size = 512
        canvas_size = grid_size * single_img_size
        
        # åˆ›å»ºç™½è‰²èƒŒæ™¯ç”»å¸ƒ
        canvas = Image.new('RGB', (canvas_size, canvas_size), (255, 255, 255))
        
        for i, img_path in enumerate(image_paths[:9]):
            try:
                with Image.open(img_path) as img:
                    img = img.convert("RGB")
                    img = img.resize((single_img_size, single_img_size))
                    
                    row = i // grid_size
                    col = i % grid_size
                    canvas.paste(img, (col * single_img_size, row * single_img_size))
            except Exception as e:
                logger.error(f"Error stitching image {img_path}: {e}")
        
        # å¦‚æœæŒ‡å®šäº†è¾“å‡ºè·¯å¾„ï¼Œä¿å­˜å›¾ç‰‡
        if output_path:
            try:
                canvas.save(output_path, format="JPEG", quality=95)
                logger.info(f"Saved stitched 9-patch grid to: {output_path}")
            except Exception as e:
                logger.error(f"Error saving stitched image to {output_path}: {e}")
                
        return self._process_pil_image(canvas)

    async def process(self, product: ProductInput) -> SceneSummary:
        logger.info(f"Summarizing product: {product.name} (Dir: {product.sample_dir})")
        logger.info(f"--- [Visual Analysis Start] ---")
        
        image_contents = []
        valid_extensions = {".jpg", ".jpeg", ".png", ".webp"}
        
        # æ ¹æ® sample_dir è·å–ç»å¯¹è·¯å¾„
        sample_path = Path(product.sample_dir)
        if not sample_path.is_absolute():
            sample_path = settings.DATA_ROOT / sample_path
        
        # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœè·¯å¾„ä¸­åŒ…å«äº†å¤šä½™çš„ data/ å‰ç¼€
        if not sample_path.exists() and "data" in sample_path.parts:
            parts = list(sample_path.parts)
            if parts.count("data") > 1:
                new_parts = []
                seen_data = False
                for p in parts:
                    if p == "data":
                        if not seen_data:
                            new_parts.append(p)
                            seen_data = True
                    else:
                        new_parts.append(p)
                sample_path = Path(*new_parts)

        # 1. åŠ è½½ä¸»å‚è€ƒå›¾ (ç”± ProductInput æŒ‡å®š)
        # éµå¾ªç”¨æˆ·æŒ‡ä»¤ï¼šå¦‚æœæ²¡æœ‰ç”Ÿæˆ white_bg_main.jpgï¼Œä½¿ç”¨ main.jpgï¼›å¦‚æœç”Ÿæˆäº†ï¼Œä½¿ç”¨ white_bg_main.jpg
        primary_img_path = Path(product.image) if not isinstance(product.image, Path) else product.image
        
        # ğŸ’¡ ä¿®å¤ï¼šé˜²å¾¡æ€§å¤„ç†è·¯å¾„å†—ä½™ï¼Œç¡®ä¿ä¸ä¼šå‡ºç° data/data/
        if not primary_img_path.is_absolute():
            # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯ 'data' å¼€å¤´
            path_parts = primary_img_path.parts
            data_name = Path(settings.DATA_ROOT).name
            if path_parts and path_parts[0] == data_name:
                primary_img_path_abs = Path(os.getcwd()) / primary_img_path
            else:
                primary_img_path_abs = Path(settings.DATA_ROOT) / primary_img_path
        else:
            primary_img_path_abs = primary_img_path
            
        # æœ€ç»ˆæ¸…ç† redundant data/data
        path_str = str(primary_img_path_abs)
        redundant_pattern = f"{data_name}{os.sep}{data_name}{os.sep}"
        if redundant_pattern in path_str:
            path_str = path_str.replace(redundant_pattern, f"{data_name}{os.sep}")
            primary_img_path_abs = Path(path_str)

        if primary_img_path_abs.exists():
            base64_img = self.encode_image(primary_img_path_abs)
            if base64_img:
                image_contents.append({
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{base64_img}"}
                })
                logger.info(f"Primary Reference Image: [USED] -> {primary_img_path_abs}")
        else:
            logger.warning(f"Primary Reference Image: [NOT FOUND] -> {primary_img_path_abs}")
            # å¤‡é€‰æ–¹æ¡ˆï¼šå¦‚æœæŒ‡å®šçš„å›¾ç‰‡ä¸å­˜åœ¨ï¼Œåˆ™å°è¯•åœ¨ sample_dir ä¸‹æœç´¢å¸¸ç”¨åç§°
            primary_candidates = [
                "white_bg_main.jpg", "white_bg_main.png", 
                "white_bg.jpg", "white_bg.png", 
                "main.jpg", "main.png"
            ]
            
            for candidate in primary_candidates:
                img_path = sample_path / candidate
                if img_path.exists():
                    base64_img = self.encode_image(img_path)
                    if base64_img:
                        image_contents.append({
                            "type": "image_url",
                            "image_url": {"url": f"data:image/jpeg;base64,{base64_img}"}
                        })
                        logger.info(f"Fallback Reference Image: [USED] -> {img_path}")
                        break
        
        # 2. åŠ è½½ detail ç›®å½•ä¸‹çš„è¯¦æƒ…å›¾ (è¿›è¡Œä¹å®«æ ¼æ‹¼æ¥é¢„å¤„ç†)
        detail_images_path = sample_path / "detail"
        if detail_images_path.exists() and detail_images_path.is_dir():
            detail_files = sorted(os.listdir(detail_images_path))
            detail_paths = []
            for filename in detail_files:
                ext = os.path.splitext(filename)[1].lower()
                if ext in valid_extensions:
                    detail_paths.append(detail_images_path / filename)
            
            if detail_paths:
                logger.info(f"Stitching {len(detail_paths)} detail images into 9-patch grids...")
                # æ¯ 9 å¼ å›¾ä¸€ç»„è¿›è¡Œæ‹¼æ¥
                for i in range(0, len(detail_paths), 9):
                    batch = detail_paths[i:i+9]
                    grid_index = i // 9 + 1
                    output_filename = f"stitched_grid_{grid_index}.jpg"
                    output_path = detail_images_path / output_filename
                    
                    stitched_base64 = self.stitch_images_9_patch(batch, output_path=output_path)
                    if stitched_base64:
                        image_contents.append({
                            "type": "image_url",
                            "image_url": {"url": f"data:image/jpeg;base64,{stitched_base64}"}
                        })
                        logger.info(f"Added stitched 9-patch grid (Batch {grid_index}, images: {len(batch)})")
        
        logger.info(f"--- [Visual Analysis Context Built: {len(image_contents)} image contents total] ---")

        if not image_contents:
            logger.warning(f"No valid images found for product {product.name} at {sample_path}")
        else:
            logger.info(f"Loaded total {len(image_contents)} images for analysis.")

        prompt_text = f"""
        äº§å“åç§°ï¼š{product.name}
        äº§å“æè¿°ï¼š{product.detail or ""}
        äº§å“è§„æ ¼å‚æ•°ï¼š{product.attributes or ""}
        
        ä»»åŠ¡ï¼š
        è¯·ä½œä¸ºä¸€åä¸“ä¸šçš„ç”µå•†è§†è§‰ç­–åˆ’ï¼Œç»“åˆäº§å“çš„åç§°ã€æè¿°ä»¥åŠè§„æ ¼å‚æ•°ï¼Œåˆ†ææä¾›çš„å‚è€ƒå›¾ç‰‡å†…å®¹ï¼Œå¹¶è¾“å‡ºæ ‡å‡†çš„ JSON æ ¼å¼æ•°æ®ã€‚

        æ­¥éª¤ 1ï¼šåˆ¤æ–­æä¾›çš„å‚è€ƒå›¾ç‰‡å†…å®¹æ˜¯å¦ä¸â€œäº§å“åç§°â€å’Œâ€œäº§å“æè¿°â€ä¸€è‡´ã€‚
        æ­¥éª¤ 2ï¼šæ€»ç»“æˆ–æ¨æ–­é€‚åˆè¯¥äº§å“çš„ä½¿ç”¨åœºæ™¯ï¼ˆå¦‚æœå›¾ç‰‡ä¸ç¬¦ï¼Œè¯·æ ¹æ®äº§å“æ–‡æœ¬æè¿°æ¨æ–­åœºæ™¯ï¼‰ã€‚

        è¾“å‡ºæ ¼å¼è¦æ±‚ï¼ˆå¿…é¡»æ˜¯åˆæ³•çš„ JSONï¼‰ï¼š
        {{
            "is_match": boolean,  // å›¾ç‰‡æ˜¯å¦ç¬¦åˆäº§å“æè¿°ï¼Œç¬¦åˆä¸º trueï¼Œä¸ç¬¦åˆä¸º false
            "mismatch_reason": string, // å¦‚æœä¸ç¬¦åˆï¼Œè¯·è¯´æ˜åŸå› ï¼›å¦‚æœç¬¦åˆï¼Œå¯ä¸ºç©ºå­—ç¬¦ä¸²
            "scene_count": integer, // æ€»ç»“çš„åœºæ™¯æ•°é‡
            "scenes": [ // åœºæ™¯åˆ—è¡¨
                {{
                    "id": integer, // åœºæ™¯åºå·
                    "scene_name": string, // åœºæ™¯åç§°
                    "description": string, // åœºæ™¯æè¿°ï¼ˆå…‰çº¿ã€æ°›å›´ï¼‰
                    "surrounding_objects": string, // å‘¨å›´ç‰©ä½“
                    "details": string, // ç»†èŠ‚å±•ç¤º
                    "selling_point": string // å–ç‚¹æè¿°ï¼ˆå…³è”åŠŸèƒ½ï¼‰
                }}
            ]
        }}

        æ³¨æ„ï¼š
        1. ç›´æ¥è¿”å› JSON å­—ç¬¦ä¸²ï¼Œä¸è¦åŒ…å« ```json æˆ–å…¶ä»– Markdown æ ‡è®°ã€‚
        2. åœºæ™¯æè¿°è¦å…·ä½“ï¼Œå…·æœ‰ç”»é¢æ„Ÿã€‚
        3. å³ä½¿å›¾ç‰‡ä¸åŒ¹é…ï¼Œä¹Ÿå¿…é¡»æ ¹æ®äº§å“æ–‡æœ¬ç”Ÿæˆåœºæ™¯æ¨èã€‚
        """
        
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt_text},
                    *image_contents
                ]
            }
        ]
        logger.debug(f"Summarizer Prompt (length={len(prompt_text)}): \n{prompt_text}")

        try:
            completion = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
            )
            content = completion.choices[0].message.content
            logger.debug(f"Raw Qwen VL response: {content}")
            
            # Simple cleanup
            if content.startswith("```json"):
                content = content[7:]
            if content.endswith("```"):
                content = content[:-3]
            
            json_data = json.loads(content)
            return SceneSummary(**json_data)
            
        except Exception as e:
            logger.error(f"Error calling Qwen VL: {e}")
            raise e
